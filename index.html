<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>HyperDreamBooth</title>
<link href="./files/style.css" rel="stylesheet">
<script type="text/javascript" src="./files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>HyperDreamBooth: HyperNetworks for Fast <br> Personalization of Text-to-Image Models</strong></h1>
  <p id="authors"><span><a href="https://natanielruiz.github.io/"></a></span><a href="https://natanielruiz.github.io/">Nataniel Ruiz</a	> <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li</a> <a href="https://varunjampani.github.io/">Varun Jampani</a> <a href="http://www.weiwei.one">Wei Wei</a> <a href="https://scholar.google.com/citations?user=u-UDZcsAAAAJ&hl=en">Tingbo Hou</a> <br>
  <a href="https://research.google/people/106214/">Yael Pritch</a> <a href="https://nealwadhwa.com">Neal Wadhwa</a> <a href="http://people.csail.mit.edu/mrub/">Michael Rubinstein</a> <a href="https://kfiraberman.github.io/">Kfir Aberman</a><br>
    <br>
  <span style="font-size: 24px">Google Research
  </span></p>
  <br>
  <img src="./files/teaser_v2.pdf" class="teaser-gif" style="width:80%;"><br>
  <h3 style="text-align:center"><em>DreamBooth: better, smaller, faster.</em></h3>
  <p>
    Using only a <i>single</i> input image, <i>HyperDreamBooth</i> is able to personalize a text-to-image diffusion model <b>25x</b> faster than DreamBooth, by using <b>(1)</b> a HyperNetwork to generate an initial prediction of a subset of network weights that are then <b>(2)</b> refined using fast finetuning for high fidelity to subject detail. Our method both <i>conserves model integrity and style diversity</i> while closely approximating the subject's essence and details.
  </p>
    <font size="+2">
          <p style="text-align: center;">
            <a href="./files/paper.pdf" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <a href="files/bibtex.txt" target="_blank">[BibTeX]</a> -->
          </p>
    </font>
</div>
<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>Personalization has emerged as a prominent aspect within the field of generative AI, enabling the synthesis of individuals in diverse contexts and styles, while retaining high-fidelity to their identities. However, the process of personalization presents inherent challenges in terms of time and memory requirements. Fine-tuning each personalized model needs considerable GPU time investment, and storing a personalized model per subject can be demanding in terms of storage capacity.
    To overcome these challenges, we propose <b>HyperDreamBooth</b> - a hypernetwork capable of efficiently generating a small set of personalized weights from a single image of a person. By composing these weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth can generate a person's face in various contexts and styles, with high subject details while also preserving the model's crucial knowledge of diverse styles and semantic modifications.
    Our method achieves personalization on faces in roughly 20 seconds, <b>25x</b> faster than DreamBooth and <b>125x</b> faster than Textual Inversion, using as few as <it>one</it> reference image, with the same quality and style diversity as DreamBooth. Also our method yields a model that is <b>10000x</b> smaller than a normal DreamBooth model.</p>
</div>
<div class="content">
  <h2>Contributions</h2>
  <p> Our work proposes to tackle the problems of <b>size</b> and <b>speed</b> of DreamBooth, while preserving <b>model integrity</b>, <b>editability</b> and <b>subject fidelity</b>. We propose the following contributions:
    <ul>
        <li><i>Lighweight DreamBooth (LiDB)</i> - a personalized text-to-image model, where the customized part is roughly 100KB of size. This is achieved by training a DreamBooth model in a low-dimensional weight-space generated by a random orthogonal incomplete basis inside of a low-rank adaptation weight space.</li><br>
        <li><i>HyperNetwork</i> architecture that leverages the Lightweight DreamBooth configuration and generates the customized part of the weights for a given subject in a text-to-image diffusion model. These provide a strong directional initialization that allows us to further finetune the model in order to achieve strong subject fidelity within a few iteration. Our method is <b>25x</b> faster than DreamBooth while achieving similar performances.</li><br>
        <li>We propose the technique of <i>rank-relaxed finetuning</i>, where the rank of a LoRA DreamBooth model is relaxed during optimization in order to achieve higher subject fidelity, allowing us to initialize the personalized model with an initial approximation using our HyperNetwork, and then approximate the high-level subject details using rank-relaxed finetuning.</li></p>
    </ul>
  <br>
</div>
<div class="content">
  <h2>HyperNetwork</h2>
  <p> Explain the hypernetwork training briefly.</p>
  <br>
  <img class="summary-img" src="./files/train_and_ft.pdf" style="width:76%;"> <br>
  <p> Explain DreamBooth Lightweight</p>
  <br>
  <img class="summary-img" src="./files/lightweight_dreambooth.png" style="width:60%;"> <br>
  <p> Explain the hypernetwork architecture briefly</p>
  <br>
  <img class="summary-img" src="./files/HeprNetwork_scheme.pdf" style="width:100%;"> <br>
  <p>Explain hypernetwork double step prediction here. </p>
  <img class="summary-img" src="./files/intermediate_hypernet.png" style="width:100%;"> <br>

</div>
<div class="content">
  <h2>Results</h2>
  <p>Explain results here. </p>
<img class="summary-img" src="./files/results_gallery.pdf" style="width:80%;">
</div>
<div class="content">
  <h2>Comparisons</h2>
  <p>Comparisons to DreamBooth and Textual Inversion.</p>
  <br>
  <img class="summary-img" src="./files/comparison.png" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>User Study and Metrics</h2>
  <p>User study and metrics</p>
  <br>
  <img class="summary-img" src="./files/novel_views.png" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>Societal Impact</h2>
  <p>This work aims to empower users with a tool for augmenting their creativity and ability to express themselves through creations in an intuitive manner. However, advanced methods for image generation can affect society in complex ways. Our proposed method inherits many possible concerns that affect this class of image generation, including altering sensitive personal characteristics such as skin color, age and gender, as well as reproducing unfair bias that can already be found in pre-trained model's training data. The underlying open source pre-trained model used in our work, Stable Diffusion, exhibits some of these concerns. All concerns related to our work have been present in the litany of recent personalization work, and the only augmented risk is that our method is more efficient and faster than previous work. In particular, we haven't found in our experiments any difference with respect to previous work on bias, or harmful content, and we have qualitatively found that our method works equally well across different ethnicities, ages, and other important personal characteristics. Nevertheless, future research in generative modeling and model personalization must continue investigating and revalidating these concerns.</p>
  <br>
</div>
<!-- <div class="content">
  <h2>BibTex</h2>
  <code> @article{ruiz2022dreambooth,<br>
  &nbsp;&nbsp;title={DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation},<br>
  &nbsp;&nbsp;author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv:2208.12242},<br>
  &nbsp;&nbsp;year={2022}<br>
  } </code> 
</div> -->
<div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>:
    We thank .
    <!-- Recycling a familiar <a href="https://chail.github.io/latent-composition/">template</a> ;). --> 
  </p>
</div>
</body>
</html>
